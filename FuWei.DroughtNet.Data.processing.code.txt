#####################################################################
### Data processing code
## DADA2 ITS workflow
rm(list=ls())
library(scales)
packageVersion("scales")
library(Rcpp)
packageVersion("Rcpp")
library("stringi")
packageVersion("stringi")
library(dada2)
packageVersion("dada2")
library(ShortRead)
packageVersion("ShortRead")
library(Biostrings)
packageVersion("Biostrings")

## Change the path to the directory containing the fataq files
path <- "~"
list.files(path)

## generate matched lists of the forward and reverse read files, as well as parsing out the sample name
fnFs <- sort(list.files(path, pattern = ".R1.fq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern = ".R2.fq", full.names = TRUE))

## cHANGE ME to your forward primer sequence
FWD <- "GTGARTCATCGAATCTTTG"
REV <- "TCCTCCGCTTATTGATATGC"

## To ensure we have the right primers, and the correct orienttion of the primers on the reads, we will verify the presence and orientation of these primers in the data
allOrients <- function(primer){
  # Create all orientation of the input sequence
  require(Biostrings)
  dna <- DNAString(primer) # The Biostrings works w/ DNAString objects rather than character vectors
  orients <- c(Forward = dna, complement = complement(dna), Reverse = reverse(dna), RevComp = reverseComplement(dna))
  return(sapply(orients, toString)) # Convert back to character vector
}
FWD.orients <- allOrients(FWD)
REV.orients <- allOrients(REV)
FWD.orients

## The presence of ambiguous bases (Ns) in the sequencing reads makes accurate mapping of short primer sequences difficult, so we'll filter them in this step (only do this in this step)
fnFs.filtN <- file.path(path, "filtN", basename(fnFs)) # Put N-filtered files in filtN/ subdirectory
fnRs.filtN <- file.path(path, "filtN", basename(fnRs))
filterAndTrim(fnFs, fnFs.filtN, fnRs, fnRs.filtN, maxN = 0, compress=FALSE, multithread = TRUE)

## We are now ready to count the number of times the primer appear in the forward and reverse read, while considering all possible primer orientations.
primerHits <- function(primer, fn){
  # Counts number of reads in which the primer is found
  nhits <- vcountPattern(primer, sread(readFastq(fn)), fixed = FALSE)
  return(sum(nhits > 0))
}
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.filtN[[1]]), 
      FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs.filtN[[1]]), 
      REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs.filtN[[1]]),
      REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.filtN[[1]]))

## After install cutadapt, we need to tell R the path to the cutadapt command
cutadapt <- "C:/Users/Wei Fu/Miniconda2/Scripts/cutadapt"
system2(cutadapt, args = "--version")

## We now create output filenames for the cutadapt-ed files, and define the parameters we are going to give the cutadapt commond.
path.cut <- file.path(path, "cutadapt")
if(!dir.exists(path.cut)) dir.create(path.cut)
fnFs.cut <- file.path(path.cut, basename(fnFs))
fnRs.cut <- file.path(path.cut, basename(fnRs))

FWD.RC <- dada2:::rc(FWD)
REV.RC <- dada2:::rc(REV)
# Trim FWD and the reverse-complement of REV off of R1
R1.flags <- paste("-g", FWD, "-a", REV.RC)
# Trim REV and the reverse-complement of FWD off of R2 (reverse reads)
R2.flags <- paste("-G", REV, "-A", FWD.RC) 
# Run Cutadapt
for(i in seq_along(fnFs)) {
  system2(cutadapt, args = c(R1.flags, R2.flags, "-n", 2, # -n 2 required to remove FWD and REV from reads
                             "-o", fnFs.cut[i], "-p", fnRs.cut[i], # output files
                             fnFs.filtN[i], fnRs.filtN[i])) # input files
}

## As a sanity check, we will count the presence of primers in the first cutadapt-ed sample:
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.cut[[1]]), 
      FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs.cut[[1]]),
      REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs.cut[[1]]), 
      REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.cut[[1]]))

## Forward and reverse fastq filenames have the format:
cutFs <- sort(list.files(path.cut, pattern = ".R1.fq", full.names = TRUE))
cutRs <- sort(list.files(path.cut, pattern = ".R2.fq", full.names = TRUE))

## Extract sample names, assuming filenames have format:
get.sample.name <- function(fname) strsplit(basename(fname), "[.]")[[1]][1]
sample.names <- unname(sapply(cutFs, get.sample.name))
head(sample.names)

## Inspect read quality profiles
# We sart by visualiziling the quality profiles of the forward reads:
plotQualityProfile(cutFs[1:2])
# Now we visualize the quality profile of the reverse reads:
plotQualityProfile(cutRs[1:2])

## Filter and trim
# Assigning the filenames for the output of the filtered reads to be stored as fastq.gz files.
filtFs <- file.path(path.cut, "filtered", basename(cutFs))
filtRs <- file.path(path.cut, "filtered", basename(cutRs))

out <- filterAndTrim(cutFs, filtFs, cutRs, filtRs, maxN = 0, maxEE = c(2, 2), 
                     truncQ = 2, minLen = 50, rm.phix = TRUE, compress = FALSE, multithread = TRUE)  # on windows, set multithread = FALSE
head(out)

## Learn the error rates
errF <- learnErrors(filtFs, multithread = FALSE)
errR <- learnErrors(filtRs, multithread = FALSE)

# Visualize the estimated error rates as a sanity check.
plotErrors(errF, nominalQ = TRUE)
plotErrors(errR, nominalQ = TRUE)

## Dereplicate identical reads
derepFs <- derepFastq(filtFs, verbose = TRUE)
derepRs <- derepFastq(filtRs, verbose = TRUE)
# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names

## Sample inference
dadaFs <- dada(derepFs, err = errF, multithread = FALSE)
dadaRs <- dada(derepRs, err = errR, multithread = FALSE)

## Merge paired reads 
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose = TRUE)

## Construct sequence table
seqtab <- makeSequenceTable(mergers)
dim(seqtab)

## Remove chimeras
seqtab.nochim <- removeBimeraDenovo(seqtab, method = "consensus", multithread=FALSE, verbose = TRUE)
table(nchar(getSequences(seqtab.nochim)))

## Track reads through the pipeline
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace
# sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denosiedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)

## Assign taxonomy with UNITE database
unite.ref <- "~"  # Change the path to the directory containing the UNITE database files
taxa <- assignTaxonomy(seqtab.nochim, unite.ref, multithread = TRUE, tryRC = TRUE)

# Inspecting the taxonomic assignments:
taxa.print <- taxa  # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)

###########################################################
## Compute alpha diversity indices
library(vegan)                                       
setwd("~")                                             # setting your working directory
asv.table <- read.csv(file = "asv_fungi_table_52000.csv", header = TRUE, row.names = 1)
head(asv.table)
t.asv.table <- t(asv.table)

richness <- specnumber(t.asv.table)                  # Species richness
shannon_diversity <- diversity(t.asv.table)           # Shannon entropy (base e)
simpson_diversity <- diversity(t.asv.table, "simpson")    # Simpson diversity
inverse_simpson <- diversity(t.asv.table, "invsimpson") # Inverse Simpson index

###########################################################
## Model fit using random forest
library(randomForest)
library(randomForestExplainer)
setwd("~")
data <- read.csv(file = "env.csv", row.names = 1)
head(data)

forest <- randomForest(AMF ~ Plant.richness + Moisture + ANPP + Bbiomass + C + N + AP + CN + pH, 
                       data = data, localImp = TRUE, importance = TRUE)
forest

min_depth_frame <- min_depth_distribution(forest)
head(min_depth_frame)

plot_min_depth_distribution(min_depth_frame)

importance_frame <- measure_importance(forest)
importance_frame

plot_multi_way_importance(importance_frame, size_measure = "no_of_nodes")

plot_multi_way_importance(importance_frame, x_measure = "mse_increase", 
                          y_measure = "node_purity_increase", 
                          size_measure = "p_value", no_of_labels = 10)

importance(forest, type = 1)
##################################################################
## Principal coordinates analysis (PCoA)
library(phyloseq)
library(ggplot2)
library(RColorBrewer)
library(vegan)

# Set working directory and read in data
setwd("~")

# Read in data
com.data <- t(read.csv(file = "amf.com.csv", header = T, row.names = 1))
com.data <- as.matrix(com.data); class(com.data) # matrix
head(com.data, 3)

sample.data <- read.csv(file = "sample.data.csv", header = T, row.names = 1)
sample.data <- as.data.frame(sample.data); class(sample.data) # data frame

sample.data$Treatment <- factor(sample.data$Treatment, levels = c("Control", "CHR", "CHRR", "INT", "INTR"))
                          
# Construct phyloseq dataset
ps <- phyloseq(otu_table(com.data, taxa_are_rows = T), sample_data(sample.data))
ps

# Using Bray-Curtis dissimilarity
ord.nmds.bray <- ordinate(ps, method = "PCoA", distance = "bray", binary = F)

p <- plot_ordination(ps, 
                     ord.nmds.bray, 
                     color = "Treatment", 
                     shape = "Type", 
                     title = "Bray PCoA of soil AMF in genus level") + 
                     geom_point(size=7, alpha = 0.75) + 
                     scale_colour_manual(values = c("#8DC63F", "#FBB040", "#F06B22", "#39B54A", "#009444"), aesthetics = c("color"))
p

# Anosim
dis.ind <- vegdist(t(otu_table(ps)), method = "bray")
anosim.treatment <- anosim(dis.ind, sample_data(ps)$Treatment, permutations = 999)
summary(anosim.treatment)


# PERMANOVA 
dis.ind <- vegdist(t(otu_table(ps)), method = "bray")
adonis.treatment <- adonis(dis.ind ~ Treatment, sample.data, permutations = 999)
adonis.treatment

##################################################################
# Redundancy Analysis (RDA)
library(adespatial)
library(vegan)
library(ggplot2)
setwd("~")

# Read data
genus.tab <- read.csv(file = "AM.fungal.genus.tab.csv", header = TRUE, row.names = 1)
genus.tab <- t(genus.tab)
head(genus.tab)

env <- read.csv(file = "env.csv", header = TRUE, row.names = 1)
head(env)
envplant <- read.csv(file = "envplant.csv", header = TRUE, row.names = 1)
head(envplant)
envchem <- read.csv(file = "envchem.csv", header = TRUE, row.names = 1)
head(envchem)

# db-RDA
(genus.amf.dbRDA <- capscale(genus.tab ~ Treatment + ANPP + C + CN + N + AP + pH + Richness, 
                           env, distance = "bray", comm = genus.tab))

anova(genus.amf.dbRDA, permutations = how(nperm = 9999))
anova(genus.amf.dbRDA, permutations = how(nperm = 9999), by = "axis")
summary(genus.amf.dbRDA)

(R2a.genus.dbRDA <- RsquareAdj(genus.amf.dbRDA)$adj.r.squared)
(R2 <- RsquareAdj(genus.amf.dbRDA)$r.squared)
vif.cca(genus.amf.dbRDA)

# using ggplot2 to make figures
genus.amf.dbRDA.scaling1 <- summary(genus.amf.dbRDA, scaling = 1) # extract scaling 1
genus.amf.dbRDA.site <- data.frame(genus.amf.dbRDA.scaling1$sites)[, 1:2]
genus.amf.dbRDA.env <- data.frame(genus.amf.dbRDA.scaling1$biplot)[, 1:2]

# read group data
group <- read.delim('group.txt', sep = '\t', stringsAsFactors = FALSE, check.names = FALSE)
group$Treatment <- factor(group$Treatment, 
                          levels =c("Control", "CHR", "CHRR", "INT", "INTR"))
# merge group information
genus.amf.dbRDA.site$sample <- row.names(genus.amf.dbRDA.site)
genus.amf.dbRDA.site <- merge(genus.amf.dbRDA.site, group, by = 'sample')
head(genus.amf.dbRDA.site)

genus.amf.dbRDA.env$sample <- NA
genus.amf.dbRDA.env$group <- row.names(genus.amf.dbRDA.env)
genus.amf.dbRDA.env <- genus.amf.dbRDA.env[5:12, ]
head(genus.amf.dbRDA.env)

p <- ggplot(genus.amf.dbRDA.site, aes(CAP1, CAP2)) +
            geom_point(aes(color = Treatment), size = 5) +
            scale_y_continuous(limits = c(-0.5, 0.5)) +
            scale_color_manual(values = c("#8DC63F", "#FBB040", "#F06B22", "#39B54A", "#009444")) +
            geom_vline(xintercept = 0, color = "gray", size = 0.5) +
            geom_hline(yintercept = 0, color = "gray", size = 0.5) +
            geom_segment(data = genus.amf.dbRDA.env, 
                         aes(x = 0,y = 0, xend = CAP1, yend = CAP2),
                         arrow = arrow(length = unit(0.1, "cm")), 
                         size = 0.3, color = "blue") +
            geom_text(data = spe.amf.dbRDA.env, aes(CAP1 * 1.1, CAP2 * 1.1, label = group), color ="blue", size = 3) +
            labs(x = 'db-RDA1 (~)', y = 'db-RDA2 (~)') + # The degree of explaination was caculated in summary(genus.amf.dbRDA) above
            theme(panel.grid = element_blank(), 
                  panel.background = element_rect(color = "black", fill ="transparent"), 
                  legend.title = element_text(), 
                  legend.key = element_rect(fill = 'transparent'), 
                  legend.position = c(0.85, 0.85))
p

# Calculating the confidence ellipses
p1 <- p + stat_ellipse(aes(color = Treatment), level = 0.65, linetype = 2)
p1

##########################################################################
## Phylogenetic analysis
library(dada2)
library(phangorn)
library(DECIPHER)
library(phyloseq)
library(ggplot2)
library(vegan)

# Set working directory
setwd("~")

# Read in data
seqtab <- read.csv(file = "seqs.csv",row.names = 1, header = T)

seqs <- getSequences(as.matrix(seqtab)); head(seqs, 3)
names(seqs) <- seqtab$Names

# Performing a multiple-alignment using the DECIPHER R package
alignment <- AlignSeqs(DNAStringSet(seqs), anchor = NA)

# Constructing a neighbor-joining (NJ) tree using the phangorn R package, and then fitted a 
# GTR+G+I maximum likelihood tree using the NJ tree as a starting point.
phang.align <- phyDat(as(alignment, "matrix"), type = "DNA")
dm <- dist.ml(phang.align)
treeNJ <- NJ(dm)
plot(treeNJ)
fit <- pml(treeNJ, data = phang.align)
fit

fitGTR <- update(fit, k = 4, inv = 0.2)
fitGTR <- optim.pml(fitGTR, model = "GTR", optInv = T, optGamma = T, 
                    rearrangement = "stochastic", control = pml.control(trace = 0))

# Constructing a phyloseq object
asvtab <- read.csv(file = "asvtab.csv", row.names = 1, header = T)
asvtab <- as.matrix(asvtab)
taxa <- read.csv(file = "taxa.csv", row.names = 1, header = T)
taxa <- as.matrix(taxa)
sample <- read.csv(file = "sample.csv", row.names = 1, header = T)
sample$Treatment <- factor(sample$Treatment, levels = c("Control","CHR", "CHRR", "INT", "INTR"))

class(asvtab)
class(taxa)
class(sample)

ps <- phyloseq(tax_table(taxa), sample_data(sample), otu_table(asvtab, taxa_are_rows = T), 
               phy_tree(fitGTR$tree))
ps

ord <- ordinate(ps, method = "PCoA", distance = "wunifrac")

p <- plot_ordination(ps, ord, color = "Treatment") + 
          geom_point(size = 5) + theme_bw() + 
          labs(title = "PCoA of soil AM fungal communities (Weighted-UniFrac)") +
          scale_color_manual(values = c("#6ABD45", "#F15B2B", "#FDBF6F", "#9E2064", "#CAB2D6")) +
          theme(axis.text.y = element_text(colour="black", size = 10, angle = 90, vjust = 1, hjust = 0.5),
                axis.text.x = element_text(colour="black", size = 10, vjust = 1, hjust = 0.5),
                axis.title.y = element_text(colour="black", size = 12),
                axis.title.x = element_text(colour="black", size = 12),
                panel.grid.minor = element_blank(),
                legend.position = c(0.90, 0.85))
p

# Analysis of similarity (Anosim) significance
wunifrac <- phyloseq::distance(ps, method = "wunifrac")
anosim.treatment <- anosim(wunifrac, sample_data(ps)$Treatment, permutations = 999)
summary(anosim.treatment)

# PERMANOVA 
wunifrac <- phyloseq::distance(ps, method = "wunifrac")
adonis.treatment <- adonis(wunifrac ~ Treatment, sample, permutations = 999)
adonis.treatment

## Calculating the net relatedness index (NRI) and nearest taxon index (NTI)
library(picante)
library(ape)
tree <- fitGTR$tree
plot(tree)
comm.data <- as.matrix(t(asvtab)); class(comm.data)

pd.result <- pd(comm.data, phy, include.root = F)
pd.result

phydist <- cophenetic(tree)
ses.mpd.result <- ses.mpd(comm.data, phydist, null.model = "independentswap", 
                          abundance.weighted = T, runs = 999)
ses.mpd.result

ses.mntd.result <- ses.mntd(comm.data, phydist, null.model = "independentswap", 
                          abundance.weighted = T, runs = 999)
ses.mntd.result


